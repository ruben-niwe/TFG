{"cells":[{"cell_type":"markdown","metadata":{"id":"i0LB6KKrf-up"},"source":["En este notebook lo que haremos será ver patrones y relaciones que tienen las disintas variables entre ellas. Para ello lo primero que haremos ser leer los datos escritos en el notebook anterior."]},{"cell_type":"markdown","metadata":{"id":"kSFSHBEJf-xZ"},"source":["Montamos drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2324,"status":"ok","timestamp":1710266866353,"user":{"displayName":"Rubén Morillas López","userId":"00851801132297737277"},"user_tz":-60},"id":"s8IYGJAEgVu5","outputId":"7eb2a98e-0ed3-4e34-ab35-18639d67fbf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","metadata":{"id":"5PlfM3uof-0M"},"source":["Cargamos las distintas rutas de los archivos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1710266866353,"user":{"displayName":"Rubén Morillas López","userId":"00851801132297737277"},"user_tz":-60},"id":"GhA3a0JWgd80","outputId":"67201751-9512-4dbe-ebf6-99bc8599720c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/My Drive/tfg/tfg/'\n","/content\n","Directorio actual: /content\n"]}],"source":["# Cambiar el directorio de trabajo\n","%cd '/content/drive/My Drive/tfg/tfg/'\n","\n","# Mostrar el directorio actual para confirmar el cambio\n","directorio_actual = %pwd\n","print(\"Directorio actual:\", directorio_actual)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3hKRxjFgjHI"},"outputs":[],"source":["import os\n","import pandas as pd\n","path_actual = os.getcwd()\n","subdirectorio = 'datas'\n","file_train = 'df_train.csv'\n","path_train = os.path.join(path_actual, subdirectorio, file_train)\n"]},{"cell_type":"markdown","metadata":{"id":"YtY3Be6FlyCN"},"source":["Leemos y metemos en un dataFrame llamado `df_train` los datos que usaremos para train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":11,"status":"error","timestamp":1710266866727,"user":{"displayName":"Rubén Morillas López","userId":"00851801132297737277"},"user_tz":-60},"id":"eoia0MSBg23Y","outputId":"74a96dc6-20d9-4e27-a4c8-75e6d2427d5e"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/datas/df_train.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-c7b89db78d37>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/datas/df_train.csv'"]}],"source":["import pandas as pd\n","\n","df_train = pd.read_csv(path_train, index_col=None)\n","df_train"]},{"cell_type":"markdown","metadata":{"id":"Q8kzUGrzl3_R"},"source":["Mostramos la matriz de correlacion en train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2eneqo3jlT8e"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Configurar el tamaño de la figura\n","plt.figure(figsize=(10, 8))\n","\n","matriz_correlacion = df_train.corr()\n","\n","# Crear un heatmap para visualizar la matriz de correlación\n","sns.heatmap(matriz_correlacion, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, square=True)\n","\n","# Mostrar el gráfico\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"lj6S6zfUgiik"},"source":["Como podemos ver en la matriz de correlacion y en el mapa de calor las variables que mas relacion tienen en nuestro caso son las varialbes hitX con hitTime. En este caso, tenemos tanta porcentaje de correlación entre una variable y otra debido a que la distancia en el eje X que viene representado por la variable `hitX` se calcula a partir del tiempo que tarda en detectarse el hit. La forma de calcular la distancia o el tiempo es con la formula $distancia = \\cfrac{distancia}{velocidad}$. Por tanto, en el clasificador lo que haremos será eliminar una variable. En nuestro caso, eliminaremos la variable hitTime.\n","\n","Otra pareja de variables que tiene también un alto indice de correlación son las variables PDGcode y trueE. En nuestro, experimento no podremos usar la variable trueE para clasificar las particulas puesto que en la vida real esta variable no es conocida, nos servirá para evaluar si la selección es mejor a una u otra energía.\n","\n","Todas las demás su relación es muy pequeña como en el caso de la variavle PGDcode y hitZ y casi nula como en el resto de relaciones entre variables.\n","\n","En nuestro caso, en la clasificación que vamos a realizar la vamos hacer a partir de la variable PGCcode, es decir el codigo de particula primaria va a ser nuestra etiqueta, por ese motivo nos interesaría que la variable PGCcode tuviera una relación más alta con alguna de las demás variables."]},{"cell_type":"markdown","metadata":{"id":"7UHdxjT3onDE"},"source":["Ahora mostraremos distintos histogramas para conocer las distribuciones de los datos en función de si son kaones o piones."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkeU3WpJoauP"},"outputs":[],"source":["# import pandas as pd\n","# import matplotlib.pyplot as plt\n","# import seaborn as sns\n","# import numpy as np\n","\n","# # Filtrar el dataframe por PDGcode\n","# df_211 = df_train[df_train['PDGcode'] == 211]\n","# df_321 = df_train[df_train['PDGcode'] == 321]\n","\n","# # Variables a visualizar\n","# variables = ['hitX', 'hitY', 'hitZ', 'hitInteg']\n","\n","# # Configurar el estilo de los gráficos\n","# sns.set(style=\"whitegrid\")\n","\n","# # Crear las visualizaciones\n","# for var in variables:\n","#     plt.figure(figsize=(10, 6))\n","\n","#     # Calcular los percentiles 1 y 99 para establecer los límites del eje x\n","#     low_percentile = np.percentile(df_train[var], 1)\n","#     high_percentile = np.percentile(df_train[var], 99)\n","\n","#     # Gráfico para PDGcode = 211\n","#     sns.histplot(df_211[var], color=\"blue\", label=\"PDGcode 211\", kde=True, stat=\"density\", linewidth=0, bins=30)\n","\n","#     # Gráfico para PDGcode = 321\n","#     sns.histplot(df_321[var], color=\"red\", label=\"PDGcode 321\", kde=True, stat=\"density\", linewidth=0, bins=30)\n","\n","#     plt.title(f'Distribución de {var} por PDGcode')\n","#     plt.xlabel(var)\n","#     plt.ylabel('Densidad')\n","\n","#     # Ajustar los límites de los ejes dinámicamente\n","#     plt.xlim(low_percentile, high_percentile)\n","\n","#     plt.legend()\n","#     plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"IvIl1_eNqRf3"},"source":["A continuación comentaremos las distribuciones de los datos en los dataFrame de train. Para ello veremos cada variable por separado. Antes de esto comentaremos que el $PDGcode = 211$ indicaria un pion, en cambio $PDGcode=321$ indicaria un kaon.\n","\n","> **hitX**: En esta variable pordemos ver como en la parte central, cuando el valor de la variable tiende más a 0, vemos como se concentra una mayor parte de piones, en cambio a medida que se va separando, vamos encontrando más kaones. Esto quiere decir que el hits de los piones se produce más cercano a donde fue lanzada esa particula, en cambio el de los kaones se produce más lejano al punto donde fueron lanzados.\n","\n","> **hitY**: Para el eje Y pasa lo mismo que en el eje X. Lo que viene a decir lo mismo, los hits de los piones se producen más cercanos al punto donde se produjo el experimento, mientras que a medida que nos vamos separando se encuentran más hits de kaones.\n","\n","> **hitZ**: En el eje Z tiene un comportamiento distinto. Si el hits se ha producido en el rango de $(-∞,+20)$ hay más probabilidad de que la particula que vamos a predecir sea un kaons y si el hits se produce en el rango $(+20, +∞)$ hay más probabilidad de que sea un pions.\n","\n","> **hitInteg**: En el caso de esta variable vemos como antes de que la magnitud de la variable sea 500 hay una mayor concentración de piones y a partir de 500 se estabilizan la cantidad de piones y kaones a medida que se incrementa el valor de la variable.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ozbbqqcxnpuw"},"source":["Como hemos visto en el valor de las variables hemos detectado un cierto patron en las posiciones de los hits en los ejes de coordenadas X,Y y Z. Por tanto, para ver un ejemplo en el espacio, vamos a representar 300 piones y 300 kaones en el eje de coordenadas, para ver como nuestro modelo pudiera llegar aprender un patrón para poder clasificar ambas variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2qHRQ40TwrHE"},"outputs":[],"source":["# import pandas as pd\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","# from mpl_toolkits.mplot3d import Axes3D\n","\n","# # Tomar 50 muestras aleatorias de cada dataframe\n","# sample_211 = df_211[['hitX', 'hitY', 'hitZ']].sample(n=300, random_state=42)\n","# sample_321 = df_321[['hitX', 'hitY', 'hitZ']].sample(n=300, random_state=42)\n","\n","# # Crear figura para la visualización 3D\n","# fig = plt.figure(figsize=(10, 8))\n","# ax = fig.add_subplot(111, projection='3d')\n","\n","# # Agregar los puntos de cada muestra al gráfico\n","# ax.scatter(sample_211['hitX'], sample_211['hitY'], sample_211['hitZ'], c='blue', marker='o', label='PDGcode 211')\n","# ax.scatter(sample_321['hitX'], sample_321['hitY'], sample_321['hitZ'], c='red', marker='^', label='PDGcode 321')\n","\n","# # Etiquetas de los ejes\n","# ax.set_xlabel('hitX')\n","# ax.set_ylabel('hitY')\n","# ax.set_zlabel('hitZ')\n","\n","# # Título y leyenda\n","# plt.title('Distribución de hits en el espacio para PDGcodes 211 y 321')\n","# ax.legend()\n","\n","# # Mostrar gráfico\n","# plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"e0_mCRzxyc8s"},"source":["Como podemos ver, las particulas de los piones tienden a estar más agrupadas en el espacio, mientras que las partículas de los kaones tienen un rango más amplio de variación en su distribución espacial."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BLta7-DL1VV4"},"outputs":[],"source":["df_train.columns"]},{"cell_type":"markdown","metadata":{"id":"wLSfSQ2G0xgb"},"source":["De todas las columnas que se muestran en la celda anterior, solo nos quedaremos para la clasificación con `hitX`, `hitY`, `hitZ` y `hitInteg`. Por esa razón se eliminan el resto de celdas a continuación."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eADAzvnu0wxX"},"outputs":[],"source":["df_train = df_train.drop(['trueE'],axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bE3oLkSW2mU2"},"outputs":[],"source":["df_train.columns"]},{"cell_type":"markdown","metadata":{"id":"he9IRECG3aXf"},"source":["Para pasarle al clasificador los datos debemos de hacer por eventos, es decir, pasarle todos los hits de un evento y la etiqueta que corresponda."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aL-HOxwS3Qb8"},"outputs":[],"source":["# Suponiendo que df es tu DataFrame\n","conteo_hits = df_train['eventID'].value_counts()\n","\n","# Para mostrar los resultados\n","print(conteo_hits)"]},{"cell_type":"markdown","metadata":{"id":"8AdLM8NM4prf"},"source":["Como podemos ver, tenemos diversos numero de hits por eventos. Al clasificador debemos de pasarle lineas con el mismo numero de eventos. Por ese motivo, debemos de elegir un numero suficiente para representar el numero de hits que le pasaremos al clasificador, en nuestro caso ese numero vendrá representado por la variable $N$. En los casos en el que el evento tenga un número menor de hits que de $N$, rellenaremos los huecos con 0, y en el caso contrario, que el evento tenga mayor numero de hits que de $N$, dejaremos los hits donde el tiempo sea mayor, es decir, se hayan producido después. Habrá que jugar con el valor de la variable $N$ para que el modelo no entrene con datos obsoletos como puede ser valores con 0 y tampoco pierda información al respecto para la clasificación.\n","\n","\n","Para ello definiremos una función, que pasandole como argumentos un dataFrame, ya que puede servir para depurar los datos de train como los de validación o test, devuelva una matriz."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kISLvXw-4pEm"},"outputs":[],"source":["import pandas as pd\n","\n","# Suponiendo que df es tu DataFrame y ya está cargado\n","\n","# Filtrando el DataFrame para las filas donde eventID == 1 y PDGcode == 321\n","filtro = (df_train['eventID'] == 3) & (df_train['PDGcode'] == 321)\n","\n","# Contando el número de filas que cumplen con el filtro\n","numero_hits = df_train[filtro].shape[0]\n","\n","# Mostrando el resultado\n","print(\"El número exacto de hits para eventID=1 con PDGcode=321 es:\", numero_hits)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XUd4uf4l9SFk"},"outputs":[],"source":["import pandas as pd\n","\n","# Suponiendo que df es tu DataFrame\n","\n","# Filtrando el DataFrame para las filas donde PDGcode == 321\n","df_filtrado = df_train[df_train['PDGcode'] == 321]\n","\n","# Obteniendo los identificadores únicos de 'eventID' en el DataFrame filtrado\n","identificadores_unicos = df_filtrado['eventID'].unique()\n","\n","# Mostrando los resultados\n","print(identificadores_unicos)\n","print(type(identificadores_unicos))\n"]},{"cell_type":"code","source":["import numpy as np\n","\n","def filtrado_datos_concatenados(df, N):\n","    # Filtrado inicial por PDGcode\n","    codes = df['PDGcode'].unique()\n","    kaones = []\n","    labels = []\n","\n","    df_filtrado = df[df['PDGcode'].isin(codes)]\n","\n","    # Identificar todos los eventIDs únicos\n","    unique_eventIDs = df_filtrado['eventID'].unique()\n","\n","    # Iterar sobre cada eventID único\n","    for eventID in unique_eventIDs:\n","        # Filtrando el DataFrame por eventID\n","        df_evento = df_filtrado[df_filtrado['eventID'] == eventID]\n","\n","        # Ordenando por hitTime en orden descendente\n","        df_evento_ordenado = df_evento.sort_values(by='hitTime', ascending=False)\n","\n","        # Ajustando el tamaño de los hits a N\n","        num_hits = min(len(df_evento_ordenado), N)\n","\n","        # Inicializando listas para cada tipo de dato\n","        hitX_values, hitY_values, hitZ_values, hitInteg_values = [], [], [], []\n","\n","        # Recolectando los valores separadamente\n","        for i in range(num_hits):\n","            hitX_values.append(df_evento_ordenado.iloc[i]['hitX'])\n","            hitY_values.append(df_evento_ordenado.iloc[i]['hitY'])\n","            hitZ_values.append(df_evento_ordenado.iloc[i]['hitZ'])\n","            hitInteg_values.append(df_evento_ordenado.iloc[i]['hitInteg'])\n","\n","        # Concatenando los valores recolectados\n","        hit_values = hitX_values + hitY_values + hitZ_values + hitInteg_values\n","\n","        # Rellenando con ceros si hay menos hits que N\n","        if len(hit_values) < 4 * N:  # 4 tipos de datos * N hits\n","            hit_values.extend([0] * (4 * N - len(hit_values)))\n","\n","        # Asegurarse de limitar a 4*N para considerar casos donde se excede\n","        kaones.append(hit_values[:4 * N])\n","        labels.append(df_evento.iloc[0]['PDGcode'])  # Tomar el PDGcode del primer hit como etiqueta\n","\n","    return np.array(kaones), np.array(labels)"],"metadata":{"id":"ngCUXP9AqvWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Numero de hits por eventos que habrá dentro de las muestras\n","N = 20"],"metadata":{"id":"uCbLWYHAtARc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["matriz_train, etiquetas_train = filtrado_datos_concatenados(df_train, N)"],"metadata":{"id":"hjafDDaDqyB9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para ver que es correcta la funcion `filtado_datos_concatenados`, el numero de identificadores únicos tiene que ser igual al numero de filas de la matriz que nos devuelve la funcion `filtado_datos_concatenados`."],"metadata":{"id":"q4CLK85QFukj"}},{"cell_type":"code","source":["print('Longitud de la matriz que nos devuelve:', len(matriz_train))\n","print('Numero de identificadores unicos en el dataset:', len(identificadores_unicos))\n","print('Numero de etiquetas:', len(etiquetas_train))"],"metadata":{"id":"fz5UGsVtEQlk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('El numero de columnas por fila debe ser:', N*4)\n","print('El numero de columnas de la matriz es:', len(matriz_train[0]))\n"],"metadata":{"id":"Bqx9fPDFIVuo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Mostramos la primera fila para ver si tienen coherencia los resultados: ')\n","print(matriz_train[0])"],"metadata":{"id":"kRVoZdqMqmBA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Estudio de la distribución del número de hits por eventos"],"metadata":{"id":"wY0j5M9PkEsE"}},{"cell_type":"markdown","source":["Como hemos visto el valor de la varaible $N$ en el estudio de nuestro problema es algo fundamental para poder entrenar con el mayor número de detalles, cuando el valor de la variable es mayor, pero a la vez si hacemos muy grande este valor, algunas columnas de nuestro dataset tendrán el valor de 0 en muchas de sus casillas.\n","\n","\n","A la vez, si intentamos reducir el valor de $N$ para evitar entrenar con valores nulos, podremos perder el detalle de las muestras.\n","\n","Para ello en esta sección estudiaremos su distribución en el conjunto train para ver los mejores valores."],"metadata":{"id":"r3yATI0kkKNj"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Suponiendo que conteo_hits es una Serie de Pandas que contiene el conteo de hits por eventID\n","# Histograma\n","plt.figure(figsize=(10, 6))\n","plt.hist(conteo_hits, bins=50, color='skyblue', edgecolor='black')\n","plt.title('Histograma del número de hits por eventID')\n","plt.xlabel('Número de hits')\n","plt.ylabel('Frecuencia')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"J5wPu_udmTNs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","plt.hist(conteo_hits, bins=10, color='skyblue', edgecolor='black')\n","plt.title('Histograma del número de hits por eventID, percentiles')\n","plt.xlabel('Número de hits')\n","plt.ylabel('Frecuencia')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"eLt_nuEnxCig"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","plt.boxplot(conteo_hits, vert=False)\n","plt.title('Diagrama de caja del número de hits por eventID')\n","plt.xlabel('Número de hits')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"i5UwBNS3n5eI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["percentiles = [0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95,0.99]\n","descripcion = conteo_hits.describe(percentiles=percentiles)\n","\n","print(descripcion)"],"metadata":{"id":"2owq0-6jn-cf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[">El histograma nos muestra una distribución que parece ser aprosimadamente normal con una ligera inclinación hacia la derecha, indicando que hay más eventos con un número menor de hits y menos eventos con un número muy alto de hits. El pico esta entorno a los 1000 hits.\n","\n",">En el diagrama de caja vemos como una mediana cernana a los 1000 hits con algunos valores atipicos que se extienden hacia el mayor número de hits. La caja que representa el ranfo intercuartílico, es estrecha en comparación con la gama de datos que tenemos, lo que sugiere que la mayoria de los datos están concentrados alrededor de la mediana.\n","\n",">En el estudio numerico vemos como los valores cercanos a la mediana representa un caso promedia tipico.\n","\n","Como vemos sería aconsejable aproximar este valor de $N$ casos promedios donde se producen mayor número de hits. Una cifra bastante asequible para empezar el entrenamiento seria con un valor de N comprendido en el rango [500,1500]. A medida que realicemos distintas prueblas con los modelos de clasificación acotaremos mucho más este valor"],"metadata":{"id":"nm5Xu2Mev85p"}},{"cell_type":"markdown","source":["## Desbalanceo de clases"],"metadata":{"id":"KLAM0Q40yZch"}},{"cell_type":"markdown","source":["En esta sección veremos si necesitamos tratar el desbalanceo de clases viendo el número de etiquetas que tenemos de kaones y de piones en train."],"metadata":{"id":"JDWvu2w6ycd0"}},{"cell_type":"code","source":["# Ahora, graficamos el histograma\n","plt.figure(figsize=(8, 4))\n","# Establecemos los bins justo entre las categorías que queremos separar\n","bins = [210.5, 321.5]  # Esto crea un bin para 211 y otro para 321\n","\n","# Dibuja el histograma\n","plt.hist(etiquetas_train, bins=bins, align='mid', color='orange', rwidth=0.8)\n","# Etiquetas para el eje x\n","plt.xticks([211, 321], ['Clase 211', 'Clase 321'])\n","\n","# Títulos y etiquetas\n","plt.title('Histograma del desbalanceo de clases con etiquetas 321 y 211')\n","plt.xlabel('Etiqueta de Clase')\n","plt.ylabel('Frecuencia')\n","\n","# Mostrar el histograma\n","plt.show()"],"metadata":{"id":"_5ghlZU2ybl7"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}